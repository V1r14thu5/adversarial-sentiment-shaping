# Adversarial Sentiment Shaping: AI, Reinforcement, and the Fragility of Sentiment-Driven Decision Systems

**Dissertation**
By Nuno Lopes

## Abstract

Sentiment indicators derived from digital discourse increasingly inform institutional decision-making in finance, governance, security, and public communication. These indicators implicitly assume that aggregated sentiment reflects authentic, independently formed human attitudes. This dissertation challenges that assumption by introducing *adversarial sentiment shaping*: a system-level phenomenon in which low-cost, well-timed linguistic interventions bias collective emotional trajectories through reinforcement, amplification, and cognitive load effects, without requiring persuasion, deception, or malicious intent.

Drawing on learning theory, cognitive load research, Cold War signal-amplification analogues, and declassified propaganda and risk-assessment doctrine, the dissertation argues that modern sentiment systems reproduce a recurring institutional failure mode: acting on amplified proxy signals as if they were calibrated measures of reality. The contribution is not a claim about individual belief manipulation, but a diagnosis of measurement fragility in environments where sentiment has become legible, actionable, and therefore targetable.

---

## Chapter 1: Introduction: Sentiment as Signal

Institutions have always relied on proxies. In complex systems, direct measurement of intent, belief, or public mood is costly, slow, or impossible. Sentiment indicators—polls, indices, dashboards, and algorithmic sentiment scores—exist to render these latent variables legible.

However, once sentiment becomes operationalized, it becomes vulnerable.

This dissertation advances the central claim that contemporary digital environments—particularly those shaped by AI-mediated language systems and engagement-optimized platforms—enable *adversarial sentiment shaping*: a process by which small, strategically timed inputs can cascade into disproportionate downstream effects. These effects emerge not through mass persuasion, but through reinforcement dynamics, participatory amplification, and feedback blindness in systems that treat sentiment as signal rather than symptom.

*This is not a novel psychological vulnerability. It is a novel scaling condition.*

## Chapter 2: From Persuasion to Reinforcement

Classical theories of influence emphasize *persuasion*: the deliberate alteration of beliefs through argument or evidence. Yet decades of empirical research in political communication suggest that persuasion effects are limited, while reinforcement effects are robust and persistent. Lazarsfeld et al.’s seminal work demonstrated that mass communication primarily reinforces existing orientations rather than converting beliefs outright¹.

Reinforcement operates through repetition, familiarity, and social rehearsal. Digital platforms dramatically reduce the cost of these mechanisms. Actions such as sharing, liking, reposting, and commenting function as low-friction repetition, independent of belief endorsement.

Adversarial sentiment shaping exploits reinforcement rather than persuasion. *It biases trajectories, not minds.*

## Chapter 3: Learning Theory and Repetition Without Belief

Hermann Ebbinghaus’ foundational research on memory demonstrated that learning follows nonlinear curves governed by repetition and temporal spacing rather than intensity². Subsequent work on the mere exposure effect further showed that repeated exposure alone can increase affective salience, even absent conscious agreement³.

Digital interaction mirrors these mechanisms:

- **Retweeting** resembles recall
- **Commenting** resembles rehearsal
- **Algorithmic resurfacing** resembles spaced repetition

Critically, learning and reinforcement do not require assent. Sentiment need not be believed to be retained, rehearsed, or amplified.

This dynamic explains how minimal initial inputs can persist and propagate through networked systems.

## Chapter 4: Cognitive Load, Doomscrolling, and Environmental Degradation

Cognitive load theory demonstrates that learning and judgment degrade under conditions of sustained interruption, emotional arousal, and attentional fragmentation⁴. Contemporary social platforms combine these conditions at scale.

Doomscrolling is not merely excessive consumption of negative information. It is repeated emotional rehearsal under uncertainty, characterized by high arousal, variable reinforcement schedules, and the absence of resolution. Under such conditions, depth of processing declines and heuristic reasoning increases⁵.

This dissertation does not claim neurological damage or clinical impairment. It advances a more limited claim: *epistemic degradation*, whereby environments reduce the reliability of signals institutions later interpret as meaningful indicators of public sentiment.

## Chapter 5: Pseudo Confirmation Bias

Classical confirmation bias refers to the tendency of individuals to preferentially seek or interpret information that confirms prior beliefs⁶. Digital systems produce a distinct phenomenon.

*Pseudo confirmation bias* refers to a system-level effect in which repeated, amplified, and algorithmically reinforced signals create the *appearance* of confirmation independent of an individual’s prior beliefs or selective information-seeking behavior.

Through participatory amplification and feedback loops, users encounter convergent sentiment cues that simulate consensus. This effect is particularly pronounced under conditions of uncertainty and cognitive load, and does not require ideological sorting or echo chambers.

*The locus of bias shifts from cognition to environment.*

## Chapter 6: AI as a Reinforcement Optimizer

Large language models operate through language—the primary interface through which humans infer intent, urgency, and consensus. AI systems do not introduce novel cognitive vulnerabilities; they operationalize existing ones.

Through feedback optimization and reinforcement learning, AI-mediated systems can adapt framing, emotional valence, and timing to maximize engagement. This produces adaptive sentiment steering even in the absence of adversarial intent.

In complex systems, harmful outcomes do not require malicious actors. *Intentionality collapses under misaligned incentives⁷.*

## Chapter 7: Historical Analogues: Cold War Signal Amplification

Cold War institutions faced analogous challenges: acting under uncertainty using proxy indicators. Declassified research conducted by RAND and other strategic institutions examined escalation dynamics, false positives, and decision-making under compressed timelines⁸.

Historical episodes such as the missile gap, bomber gap, and Able Archer 83 illustrate how amplified perception can drive disproportionate responses despite limited empirical grounding⁹.

These cases are not presented as empirical evidence for contemporary claims, but as illustrative analogues of a recurring failure mode: *acting on proxy signals as if they were calibrated measures of reality.*

## Chapter 8: Propaganda, Panic, and Unwitting Amplification

Soviet propaganda theory emphasized indirect reinforcement through unwitting intermediaries rather than direct persuasion¹⁰. Narratives were designed to be repeated socially, normalized through participation, and emotionally framed to compress deliberation.

U.S. psychological operations doctrine similarly distinguishes persuasion from reinforcement, emphasizing repetition, credibility via intermediaries, and emotional salience¹¹.

Modern digital environments reproduce these dynamics structurally. Highly informed users may nonetheless function as non-conscious amplifiers under conditions of cognitive load and emotional intensity.

## Chapter 9: Measurement Drift and Feedback Blindness

When sentiment indicators become operational inputs, they become targets. This follows Goodhart’s Law: *when a measure becomes a target, it ceases to be a good measure¹².*

Sentiment systems exhibit:

- Drift over time
- Volatility amplification
- Reduced predictive fidelity
- Second-order feedback blindness

Institutions act on signals they themselves help generate. Fact-checking addresses factual claims but does not address emotional momentum or reinforcement dynamics.

## Chapter 10: Methodological Orientation

This dissertation analyzes signal dynamics, not individual belief change. The empirical program focuses on time-series distortion, reinforcement curves, amplification asymmetry, sentiment persistence, and network diffusion.

*The unit of analysis is the trajectory, not the individual.*

## Chapter 11: Scope, Ethics, and Limitations

This work explicitly excludes clinical mental health claims, neurological mechanisms, attribution of malicious intent, and content regulation proposals. The ethical concern is measurement integrity, not speech control.

## Chapter 12: Institutional Implications

Institutions respond to legible signals rather than truth. Sentiment systems trade fidelity for speed. Adversarial sentiment shaping exploits this tradeoff, producing compressed decision timelines and overreaction to noise.

*The appropriate response lies in measurement governance, not censorship.*

## Chapter 13: Conclusion: Epistemic Fragility in an AI-Mediated World

Adversarial sentiment shaping is not new. Reinforcement, repetition, and amplification have long shaped perception under uncertainty. AI renders these dynamics scalable, adaptive, and persistent.

The central risk is not persuasion, but *epistemic fragility*: institutions mistaking amplified sentiment for calibrated signal.

---

## References

1. Lazarsfeld, P., Berelson, B., & Gaudet, H. (1944). *The People’s Choice*. Columbia University Press.
2. Ebbinghaus, H. (1885). *Über das Gedächtnis*. Leipzig.
3. Zajonc, R. (1968). “Attitudinal Effects of Mere Exposure.” *Journal of Personality and Social Psychology*.
4. Sweller, J. (1988). “Cognitive Load During Problem Solving.” *Cognitive Science*.
5. Kahneman, D. (2011). *Thinking, Fast and Slow*. Farrar, Straus and Giroux.
6. Nickerson, R. (1998). “Confirmation Bias.” *Review of General Psychology*.
7. Perrow, C. (1984). *Normal Accidents*. Princeton University Press.
8. RAND Corporation. (1950s–1970s). Declassified escalation and deterrence studies.
9. Allison, G. (1971). *Essence of Decision*. Little, Brown.
10. Ellul, J. (1965). *Propaganda: The Formation of Men’s Attitudes*. Knopf.
11. U.S. Army. *Field Manual 33-1: Psychological Operations* (declassified).
12. Goodhart, C. (1975). “Problems of Monetary Management.”
